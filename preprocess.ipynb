{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0su1327/Graduation_Thesis/blob/Data-Anaylsis/preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a739673",
      "metadata": {
        "id": "8a739673"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import h5py\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "def get_service_list(dirname='list', filename='service.txt'):\n",
        "    print('Getting service list...')\n",
        "    with open(os.path.join(dirname, filename), 'r') as service:\n",
        "        service_list = service.read().split('\\n')\n",
        "    return service_list\n",
        "\n",
        "\n",
        "def get_flag_list(dirname='list', filename='flag.txt'):\n",
        "    print('Getting flag list...')\n",
        "    with open(os.path.join(dirname, filename), 'r') as flag:\n",
        "        flag_list = flag.read().split('\\n')\n",
        "    return flag_list\n",
        "\n",
        "\n",
        "def get_data_frame(dirname='dataset', filename=None):\n",
        "    if filename is None:\n",
        "        raise ValueError('File name should be set.')\n",
        "    print('Getting data frame from a file...')\n",
        "    print('Reading file:', os.path.join(dirname, filename))\n",
        "    df = pd.read_csv(os.path.join(dirname, filename), header=None)\n",
        "    return df\n",
        "\n",
        "\n",
        "def to_numeric(data_frame, service_list, flag_list, test=False, attack=False, save=True):\n",
        "    if test and attack:\n",
        "        raise ValueError('Test data cannot have attack logs.')\n",
        "    df = data_frame\n",
        "\n",
        "    if not test:\n",
        "        if not attack:\n",
        "            # extract only normal data\n",
        "            print('Data size before normal data extraction:', df.shape)\n",
        "            # index 41: label (index number starts from 0)\n",
        "            df = df[df[41] == 'normal'].copy()\n",
        "            print('Data size after normal data extraction:', df.shape)\n",
        "        else:\n",
        "            # extract 99% normal data and 1% attack data\n",
        "            print('Data size before normal data extraction:', df.shape)\n",
        "            # index 41: label (index number starts from 0)\n",
        "            df_normal_copy = df[df[41] == 'normal'].copy()\n",
        "            df_normal = df_normal_copy.sample(n=int(df_normal_copy.shape[0] * 0.99), random_state=1398)\n",
        "            df_attack = df[df[41] != 'normal'].sample(n=int(df_normal_copy.shape[0] * 0.01) + 1, random_state=1398)\n",
        "            print('Number of normal records:', len(df_normal))\n",
        "            print('Number of attack records:', len(df_attack))\n",
        "            df = pd.concat((df_normal, df_attack))\n",
        "            print('Data size of concatenated data:', df.shape)\n",
        "        df = shuffle(df, random_state=1398)\n",
        "\n",
        "    # index 1: protocol_type\n",
        "    print('Replacing protocol_type values to numeric...')\n",
        "    df[1].replace(['tcp', 'udp', 'icmp'], range(3), inplace=True)\n",
        "\n",
        "    # index 2: service\n",
        "    print('Replacing service values to numeric...')\n",
        "    df[2].replace(service_list, range(len(service_list)), inplace=True)\n",
        "\n",
        "    # index 3: flag\n",
        "    print('Replacing flag values to numeric...')\n",
        "    df[3].replace(flag_list, range(len(flag_list)), inplace=True)\n",
        "\n",
        "    # 전체 특성을 모두 사용하는 경우\n",
        "    # 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42\n",
        "\n",
        "    # 특성중요도 알고리즘을 사용하여 추출한 특성만 사용하는 경우\n",
        "    # 1, 2, 3, 4, 5, 7, 11, 31, 32, 33, 34, 35, 36, 38, 39, 42\n",
        "\n",
        "    # PI + Drop Column 사용하는 경우\n",
        "    # 1, 2, 3, 4, 6, 7, 11, 34, 36, 38\n",
        "    if not test:\n",
        "        # extract only the same features from Kyoto 2006+ dataset\n",
        "        df = df.loc[:, [1, 2, 3, 4, 6, 7, 11, 34, 36, 38]]\n",
        "    else:\n",
        "        # include label\n",
        "        df = df.loc[:, [1, 2, 3, 4, 6, 7, 11, 34, 36, 38, 41]]\n",
        "        df[41] = df[41].map(lambda x: 0 if x == 'normal' else 1)  # normal 0, attack 1\n",
        "\n",
        "    # save as csv file\n",
        "    if save:\n",
        "        if not os.path.exists('csv'):\n",
        "            os.makedirs('csv')\n",
        "        if not test:\n",
        "            if not attack:\n",
        "                print('Saving file:', os.path.join('csv', 'train_normal_numeric.csv'))\n",
        "                df.to_csv(os.path.join('csv', 'train_normal_numeric.csv'))\n",
        "            else:\n",
        "                print('Saving file:', os.path.join('csv', 'train_mixed_numeric.csv'))\n",
        "                df.to_csv(os.path.join('csv', 'train_mixed_numeric.csv'))\n",
        "        else:\n",
        "            print('Saving file:', os.path.join('csv', 'test_numeric.csv'))\n",
        "            df.to_csv(os.path.join('csv', 'test_numeric.csv'))\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def to_machine_readable(data_frame, service_list, flag_list, test=False, attack=False, save_csv=True):\n",
        "    if test and attack:\n",
        "        raise ValueError('Test data cannot have attack logs.')\n",
        "    df = data_frame\n",
        "    sc = MinMaxScaler()\n",
        "    enc = OneHotEncoder(categories=[range(3), range(len(service_list)), range(len(flag_list))])\n",
        "    num_desc = df.loc[:, [4]].describe()\n",
        "    # 전체 사용하면 0, 4, 5\n",
        "    # 특성추출 해서 나온 것만 사용하면 4, 5\n",
        "\n",
        "\n",
        "    # extract and drop label\n",
        "    label, df_label = [], []\n",
        "    if test:\n",
        "        label = df[41].copy().values.reshape((df.shape[0], 1))\n",
        "        df_label = pd.DataFrame(label)\n",
        "        df.drop([41], axis=1, inplace=True)\n",
        "\n",
        "\n",
        "    # 전체 사용하면 0, 4, 5\n",
        "    # 특성추출 해서 나온 것만 사용하면 4, 5\n",
        "    # index 0, 4, 5: duration, src_bytes, dst_bytes (in kyoto: index 0, 2, 3)\n",
        "    attr_name = ['duration', '', '', '', 'src_bytes', 'dst_bytes']\n",
        "    for i in [4]:\n",
        "        print('Converting {0} data (index {1}) to machine readable...'.format(attr_name[i], i))\n",
        "        iqr = (num_desc[i].values[6] - num_desc[i].values[4]) # 75% - 25%\n",
        "        std = num_desc[i].values[6] + iqr * 1.5  # IQR upper fence = Q3(75%) + 1.5 * IQR\n",
        "        if std == 0:\n",
        "            df[i] = df[i].map(lambda x: 1 if x > 0 else 0)\n",
        "        else:\n",
        "            df[i] = df[i].map(lambda x: std if x > std else x)\n",
        "    sc.fit(df[[4]].values)\n",
        "    df[[4]] = sc.transform(df[[4]].values)\n",
        "\n",
        "\n",
        "    # 모든 특성을 사용하는 경우 float 값으로 변환해줘야 하는 인덱스값들\n",
        "    # 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 31, 32, 42\n",
        "\n",
        "    # 특성중요도 알고리즘으로 추출한 특성만 사용하는 경우에 float 값으로 변환해줘야 하는 인덱스값들\n",
        "    #  7, 11, 31, 32, 33, 34, 35, 36, 38, 39, 42\n",
        "\n",
        "    # PI + Drop Column 사용하는 경우\n",
        "    #  4, 6, 7, 11, 34, 36, 38\n",
        "    print('Converting count data (index 22, 31, 32) to machine readable...')\n",
        "    sc.fit(df[[4, 6, 7, 11, 34, 36, 38 ]].values.astype(np.float32))\n",
        "    df[[4, 6, 7, 11, 34, 36, 38 ]] = sc.transform(df[[4, 6, 7, 11, 34, 36, 38 ]].values.astype(np.float32))\n",
        "\n",
        "    # index 1, 2, 3: protocol_type, service, flag (in kyoto: index 23, 1, 13)\n",
        "    print('Converting type data (index 1, 2, 3) to machine readable...')\n",
        "    enc.fit(df[[1, 2, 3]].values)\n",
        "    one_hot_arr = enc.transform(df[[1, 2, 3]].values).toarray()\n",
        "\n",
        "    # drop one-hot data and attach it again\n",
        "    print('Dropping and attaching one-hot encoding data...')\n",
        "    df.drop([1, 2, 3], axis=1, inplace=True)\n",
        "    df_final = np.concatenate((df.values, one_hot_arr), axis=1)\n",
        "    df_final = pd.DataFrame(df_final)\n",
        "\n",
        "    # print shape of data frame\n",
        "    print('Final shape of data:', df_final.shape)\n",
        "    if test:\n",
        "        print('Final shape of label', df_label.shape)\n",
        "\n",
        "    # save data frame into csv format\n",
        "    if save_csv:\n",
        "        if not os.path.exists('csv'):\n",
        "            os.makedirs('csv')\n",
        "        if not test:\n",
        "            if not attack:\n",
        "                print('Saving file:', os.path.join('csv', 'train_normal_final.csv'))\n",
        "                df_final.to_csv(os.path.join('csv', 'train_normal_final.csv'), index=False)\n",
        "            else:\n",
        "                print('Saving file:', os.path.join('csv', 'train_mix_final.csv'))\n",
        "                df_final.to_csv(os.path.join('csv', 'train_mix_final.csv'), index=False)\n",
        "        else:\n",
        "            print('Saving file:', os.path.join('csv', 'test_feature_final.csv'))\n",
        "            df_final.to_csv(os.path.join('csv', 'test_feature_final.csv'), index=False)\n",
        "            print('Saving file:', os.path.join('csv', 'test_label_final.csv'))\n",
        "            df_label.to_csv(os.path.join('csv', 'test_label_final.csv'), index=False)\n",
        "\n",
        "    # save into hdf5 format\n",
        "    if not os.path.exists(os.path.join('..', 'hdf5')):\n",
        "        os.makedirs(os.path.join('..', 'hdf5'))\n",
        "    if not test:\n",
        "        if not attack:\n",
        "            with h5py.File(os.path.join('..', 'hdf5', 'train_normal.hdf5'), 'w') as hdf:\n",
        "                print('Saving file:', os.path.join('..', 'hdf5', 'train_normal.hdf5'))\n",
        "                hdf['x'] = df_final.values[:]\n",
        "        else:\n",
        "            with h5py.File(os.path.join('..', 'hdf5', 'train_mix.hdf5'), 'w') as hdf:\n",
        "                print('Saving file:', os.path.join('..', 'hdf5', 'train_mix.hdf5'))\n",
        "                hdf['x'] = df_final.values[:]\n",
        "    else:\n",
        "        with h5py.File(os.path.join('..', 'hdf5', 'test.hdf5'), 'w') as hdf:\n",
        "            print('Saving file:', os.path.join('..', 'hdf5', 'test.hdf5'))\n",
        "            hdf['x'] = df_final.values[:]\n",
        "            hdf['y'] = df_label[:]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}